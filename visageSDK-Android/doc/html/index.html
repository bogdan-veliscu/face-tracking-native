<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.10"/>
<title>visageSDK: API</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.10 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">API </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>The following section provides an overview of key functionalities, gives links to most important classes and relevant sample projects, and lists required libraries to link. The detailed information is found in the documentation of each class, reached through links in this section or links on the side menu, or through class reference.</p>
<p>visage|SDK provides three libraries:</p><ul>
<li><em>libVisageVision.so</em> - face detection, alignment and face tracking</li>
<li><em>libVisageGaze.so</em> - screen space gaze tracking (requires <em>libVisageVision.so</em>)</li>
<li><em>libVisageAnalyser.so</em> - face analysis and recognition (requires <em>libVisageVision.so</em>)</li>
</ul>
<h1><a class="anchor" id="visageVision-t"></a>
Facial features tracking</h1>
<p>Visage tracker tracks multiple faces and facial features in video sequences and outputs 3D head pose, facial expressions, gaze direction, facial feature points and textured 3D face model. The tracker is fully configurable in terms of performance, quality, tracked features and facial actions, as well as other options, allowing in effect a variety of customized trackers suited to different applications. Several common configurations are delivered. Details about configuring the tracker can be found in the <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a>.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageTracker.html" title="VisageTracker is a face tracker capable of tracking the head pose, facial features and gaze for multi...">VisageTracker</a>: Tracks multiple faces and facial features in video coming from file, camera or other source.</li>
<li><a class="el" href="classVisageSDK_1_1VisageGazeTracker.html" title="VisageGazeTracker extends VisageTracker functionality, adding screen space gaze tracking on top of fa...">VisageGazeTracker</a>: Extends <a class="el" href="classVisageSDK_1_1VisageTracker.html" title="VisageTracker is a face tracker capable of tracking the head pose, facial features and gaze for multi...">VisageTracker</a> functionality adding screen space gaze tracking on top of facial features/head tracking.</li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a>: Used to return tracking results from the tracker.</li>
</ul>
<p>Face tracking is demonstrated in VisageTrackerDemo and VisageTrackerUnity sample project.</p>
<h1><a class="anchor" id="visageVision-d"></a>
Facial feature detection</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a> detects faces and facial features in input images. The results are, for each detected face, the 3D head pose, the coordinates of facial feature points, e.g. chin tip, nose tip, lip corners etc. and 3D face model fitted to the face. The results are returned in one or more <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects, one for each detected face.</p>
<p>The FaceDetectDemo sample project demonstrates facial features detection.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a>: Detects facial features in still images.</li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a>: Used to return detection results from detector.</li>
</ul>
<h1><a class="anchor" id="visageVision-a"></a>
Facial feature analysis</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFaceAnalyser.html" title="VisageFaceAnalyser contains face analysis algorithms capable of estimating age, gender and emotion fr...">VisageFaceAnalyser</a> contains face analysis algorithms capable of estimating gender and emotion from frontal facial images (yaw between -20 and 20 degrees). For gender estimation it returns estimated gender and for emotions estimation it returns the probability of each of estimated facial emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.</p>
<p>The FaceDetectDemo sample demonstrate gender and emotion estimation.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFaceAnalyser.html" title="VisageFaceAnalyser contains face analysis algorithms capable of estimating age, gender and emotion fr...">VisageFaceAnalyser</a>: Face analyser capable of estimating gender and emotion from frontal facial images (yaw between -20 and 20 degrees).</li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a>: Used to pass the necessary facial image data to <a class="el" href="classVisageSDK_1_1VisageFaceAnalyser.html" title="VisageFaceAnalyser contains face analysis algorithms capable of estimating age, gender and emotion fr...">VisageFaceAnalyser</a> functions.</li>
</ul>
<h1><a class="anchor" id="visageVision-r"></a>
Face recognition</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFaceRecognition.html" title="VisageFaceRecognition class contains a face recognition algorithm capable of measuring similarity bet...">VisageFaceRecognition</a> contains a face recognition algorithm capable of measuring similarity between human faces and recognizing a person's identity from frontal facial images (yaw angle approximately from -20 to 20 degrees). It returns name of the person with the most similar face found in the current gallery.</p>
<p>The FaceDetectDemo sample demonstrates face recognition.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFaceRecognition.html" title="VisageFaceRecognition class contains a face recognition algorithm capable of measuring similarity bet...">VisageFaceRecognition</a>: Measures similarity between human faces and recognizes a person's identity from frontal facial images (yaw angle approximately from -20 to 20 degrees). </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.10
</small></address>
</body>
</html>
