<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>visageSDK: API</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">API </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Visage|SDK consists of static libraries libVisageVision, libVisageGaze and libVisageAnalyser. It also uses third party libraries libstdc++ and libXML.</p>
<p>The following section provides an overview of key functionalities, gives links to most important classes and relevant sample projects, and lists required libraries to link. The detailed information is found in the documentation of each class, reached through links in this section or links on the side menu, or through class reference.</p>
<p>visage|SDK provides three libraries:</p><ul>
<li><em>libVisageVision.a</em> - face detection, alignment and face tracking</li>
<li><em>libVisageGaze.a</em> - screen space gaze tracking (requires <em>libVisageVision.a</em>)</li>
<li><em>libVisageAnalyser.a</em> - face analysis and recognition (requires <em>libVisageVision.a</em> and <em>Accelerate.framework (CBLAS)</em> )</li>
</ul>
<h1><a class="anchor" id="visageVision-t"></a>
Facial features tracking</h1>
<p>Visage tracker tracks multiple faces and facial features in video sequences and outputs 3D head pose, facial expressions, gaze information, eye closure, facial feature points and full 3D face model. The tracker is fully configurable in terms of performance, quality, as well as other options. Common configurations are delivered. Details about configuring the tracker can be found in the <a href="../VisageTracker Configuration Manual.pdf">VisageTracker Configuration Manual</a>.</p>
<p>Face tracking is demonstrated in VisageTrackerDemo, VisageTrackerUnity and FacialAnimationUnity sample projects.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageTracker.html" title="VisageTracker is a face tracker capable of tracking the head pose, facial features and gaze for multi...">VisageTracker</a>: Tracks multiple faces and facial features.</li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a>: Used to return tracking results from the tracker.</li>
<li><a class="el" href="classVisageSDK_1_1VisageGazeTracker.html" title="VisageGazeTracker extends VisageTracker functionality, adding screen space gaze tracking on top of fa...">VisageGazeTracker</a>: Screen-space gaze position tracking.</li>
</ul>
<h1><a class="anchor" id="visageVision-d"></a>
Facial feature detection</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a> detects faces and facial features in input images. The results are, for each detected face, the 3D head pose, gaze direction, eye closure, the coordinates of facial feature points, e.g. chin tip, nose tip, lip corners etc. and 3D face model fitted to the face. The results are returned in one or more <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects, one for each detected face.</p>
<p>The FaceDetectDemo sample project demonstrates facial features detection.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a>: Detects faces and facial features in still images.</li>
<li><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a>: Used to return detection results from detector.</li>
</ul>
<h1><a class="anchor" id="visageVision-a"></a>
Face analysis</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFaceAnalyser.html" title="VisageFaceAnalyser contains face analysis algorithms capable of estimating age, gender and emotion fr...">VisageFaceAnalyser</a> contains face analysis algorithms capable of estimating age, gender and emotion from frontal facial images (yaw between -20 and 20 degrees). For age estimation it returns estimated age, for gender estimation it returns estimated gender and for emotions estimation it returns the probability of each of estimated facial emotions: anger, disgust, fear, happiness, sadness, surprise and neutral.</p>
<p>The FaceDetectDemo sample demonstrates age, gender and emotion estimation.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFaceAnalyser.html" title="VisageFaceAnalyser contains face analysis algorithms capable of estimating age, gender and emotion fr...">VisageFaceAnalyser</a>: Face analyser capable of estimating age, gender and emotion from frontal facial images (yaw between -20 and 20 degrees).</li>
</ul>
<h1><a class="anchor" id="visageVision-r"></a>
Face recognition</h1>
<p>The class <a class="el" href="classVisageSDK_1_1VisageFaceRecognition.html" title="VisageFaceRecognition class contains a face recognition algorithm capable of measuring similarity bet...">VisageFaceRecognition</a> contains a face recognition algorithm capable of measuring similarity between human faces and recognizing a person's identity from frontal facial image (yaw angle approximately from -20 to 20 degrees) by comparing it to faces previously stored in a gallery.</p>
<p>The FaceDetectDemo sample demonstrates face recognition.</p>
<p><b>Main classes</b></p><ul>
<li><a class="el" href="classVisageSDK_1_1VisageFaceRecognition.html" title="VisageFaceRecognition class contains a face recognition algorithm capable of measuring similarity bet...">VisageFaceRecognition</a>: Measures similarity between human faces and recognizes a person's identity from frontal facial images (yaw angle approximately from -20 to 20 degrees). </li>
</ul>
</div></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
