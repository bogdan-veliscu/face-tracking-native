<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.10"/>
<title>visageSDK: VisageSDK::VisageFeaturesDetector Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.10 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="files.html"><span>Files</span></a></li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="hierarchy.html"><span>Class&#160;Hierarchy</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>VisageSDK</b></li><li class="navelem"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html">VisageFeaturesDetector</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classVisageSDK_1_1VisageFeaturesDetector-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">VisageSDK::VisageFeaturesDetector Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Faces and facial features detector implementation.  
 <a href="classVisageSDK_1_1VisageFeaturesDetector.html#details">More...</a></p>

<p><code>#include &lt;<a class="el" href="VisageFeaturesDetector_8h_source.html">VisageFeaturesDetector.h</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:ac4a75ef862227ed7edd84c9a621dce9d"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="ac4a75ef862227ed7edd84c9a621dce9d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#ac4a75ef862227ed7edd84c9a621dce9d">VisageFeaturesDetector</a> ()</td></tr>
<tr class="memdesc:ac4a75ef862227ed7edd84c9a621dce9d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor. <br /></td></tr>
<tr class="separator:ac4a75ef862227ed7edd84c9a621dce9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2b5ccb544e23a6255c88476b18dd928b"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a2b5ccb544e23a6255c88476b18dd928b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#a2b5ccb544e23a6255c88476b18dd928b">~VisageFeaturesDetector</a> ()</td></tr>
<tr class="memdesc:a2b5ccb544e23a6255c88476b18dd928b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor. <br /></td></tr>
<tr class="separator:a2b5ccb544e23a6255c88476b18dd928b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad23a5d91f896b82fa7f88dc3b9532e1a"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#ad23a5d91f896b82fa7f88dc3b9532e1a">Initialize</a> (const char *path)</td></tr>
<tr class="memdesc:ad23a5d91f896b82fa7f88dc3b9532e1a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialise the feature detector.  <a href="#ad23a5d91f896b82fa7f88dc3b9532e1a">More...</a><br /></td></tr>
<tr class="separator:ad23a5d91f896b82fa7f88dc3b9532e1a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a2ad8770f7f369325acabd6ebc3ef1cea"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#a2ad8770f7f369325acabd6ebc3ef1cea">detectFaces</a> (VsImage *frame, VsRect *faces, int maxFaces=1, float minFaceScale=0.1f, float maxFaceScale=1.0f, bool useRefinementStep=true)</td></tr>
<tr class="memdesc:a2ad8770f7f369325acabd6ebc3ef1cea"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs face detection in a still image.  <a href="#a2ad8770f7f369325acabd6ebc3ef1cea">More...</a><br /></td></tr>
<tr class="separator:a2ad8770f7f369325acabd6ebc3ef1cea"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa8163511b6cb27676b7c0145ab24a3a0"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#aa8163511b6cb27676b7c0145ab24a3a0">detectFacialFeatures</a> (VsImage *frame, <a class="el" href="structVisageSDK_1_1FaceData.html">FaceData</a> *output, int maxFaces=1, float minFaceScale=0.1f, float maxFaceScale=1.0f, bool outputOnly2DFeatures=false)</td></tr>
<tr class="memdesc:aa8163511b6cb27676b7c0145ab24a3a0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Performs faces and facial features detection in a still image.  <a href="#aa8163511b6cb27676b7c0145ab24a3a0">More...</a><br /></td></tr>
<tr class="separator:aa8163511b6cb27676b7c0145ab24a3a0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Faces and facial features detector implementation. </p>
<p>This class can be used to detect one or more faces and their facial features in an image. The input is an image bitmap or an image file in one of the supported file formats: JPEG, PNG, BMP or PPM.</p>
<p>Function <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#a2ad8770f7f369325acabd6ebc3ef1cea">detectFaces()</a> performs a fast face detection on the image. The result is, for each detected face, a VsRect object containing facial bounding box.</p>
<p>Function <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#aa8163511b6cb27676b7c0145ab24a3a0">detectFacialFeatures()</a> performs a face and facial features detection on the image. The results is, for each detected face, <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> object containing 3D head pose, coordinates of facial feature points (e.g. pupils, nose tip, lip corners etc.), 3D face model fitted to the face and more. Please refer to the <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> documentation for detailed description of returned data.</p>
<p>To use the detector, it must first be initialized by calling the function <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html#ad23a5d91f896b82fa7f88dc3b9532e1a">Initialize()</a>.</p>
<p>Implemented in libVisageVision.lib</p>
<p>Demonstrated in <a href="../../../Samples/OpenGL/build/msvc140/FaceDetector/doc/index.html">FaceDetector</a> sample project. </p>

<p>Definition at line <a class="el" href="VisageFeaturesDetector_8h_source.html#l00068">68</a> of file <a class="el" href="VisageFeaturesDetector_8h_source.html">VisageFeaturesDetector.h</a>.</p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a2ad8770f7f369325acabd6ebc3ef1cea"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::VisageFeaturesDetector::detectFaces </td>
          <td>(</td>
          <td class="paramtype">VsImage *&#160;</td>
          <td class="paramname"><em>frame</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VsRect *&#160;</td>
          <td class="paramname"><em>faces</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>maxFaces</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>minFaceScale</em> = <code>0.1f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>maxFaceScale</em> = <code>1.0f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>useRefinementStep</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs face detection in a still image. </p>
<p>The algorithm detects one or more faces. For each detected face a square facial bounding box is returned.</p>
<p>The results are returned in form of VsRect objects. An array of VsRect objects passed to this method as output parameter should be allocated to maxFaces size. For example:</p>
<div class="fragment"><div class="line">VsRect* faces = <span class="keyword">new</span> VsRect[maxFaces];</div>
<div class="line"></div>
<div class="line">n = this-&gt;m_Detector-&gt;detectFaces(image, faces, maxFaces);</div>
</div><!-- fragment --><p>After this call, n contains the number of detected faces. The first n members of the faces array are filled with resulting bounding boxes for each detected face. If maxFaces is smaller than the number of faces actually detected in the image, the function will return only first maxFaces detected faces.</p>
<p>VsImage is the image storage class similar to IplImage from OpenCV, it has the same structure and members so it can be used like IplImage. Please refer to OpenCV documentation for details of accessing IplImage data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</p>
<p>Following image formats are supported:</p><ul>
<li>VISAGE_FRAMEGRABBER_FMT_RGB: each pixel of the image is represented by three bytes representing red, green and blue channels, respectively.</li>
<li>VISAGE_FRAMEGRABBER_FMT_RGBA: each pixel of the image is represented by four bytes representing red, green, blue and alpha (ignored) channels, respectively.</li>
<li>VISAGE_FRAMEGRABBER_FMT_LUMINANCE: each pixel of the image is represented by one byte representing the luminance (gray level) of the image. Origin must be:</li>
<li>VISAGE_FRAMEGRABBER_ORIGIN_TL: Origin is the top left pixel of the image. Pixels are ordered row-by-row starting from top left.</li>
</ul>
<p>Note that the input image is internally converted to grayscale.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>the input image. </td></tr>
    <tr><td class="paramname">faces</td><td>pointer to an array of VsRect objects in which the results will be returned. </td></tr>
    <tr><td class="paramname">maxFaces</td><td>maximum number of faces to be detected </td></tr>
    <tr><td class="paramname">minFaceScale</td><td>scale of smallest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height)) </td></tr>
    <tr><td class="paramname">maxFaceScale</td><td>scale of largest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height)) </td></tr>
    <tr><td class="paramname">useRefinementStep</td><td>if set to true, additional refinement algorithm will be used resulting with more precise facial bounding boxes and lower FPR, but higher detection time </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>number of detected faces (0 or more) </dd></dl>

</div>
</div>
<a class="anchor" id="aa8163511b6cb27676b7c0145ab24a3a0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageSDK::VisageFeaturesDetector::detectFacialFeatures </td>
          <td>(</td>
          <td class="paramtype">VsImage *&#160;</td>
          <td class="paramname"><em>frame</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structVisageSDK_1_1FaceData.html">FaceData</a> *&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>maxFaces</em> = <code>1</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>minFaceScale</em> = <code>0.1f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>maxFaceScale</em> = <code>1.0f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>outputOnly2DFeatures</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Performs faces and facial features detection in a still image. </p>
<p>The algorithm detects one or more faces and their features. The results are, for each detected face, the 3D head pose, gaze direction, eye closure, the coordinates of facial feature points (e.g. chin tip, nose tip, lip corners etc.) and 3D face model fitted to the face. If outputOnly2DFeatures is set, only the 2D feature points will be returned.</p>
<p>The results are returned in form of <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects. An array of <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects passed to this method as output parameter should be allocated to maxFaces size. For example:</p>
<div class="fragment"><div class="line">FaceData* data = <span class="keyword">new</span> FaceData[maxFaces];</div>
<div class="line"></div>
<div class="line">n = this-&gt;m_Detector-&gt;detectFacialFeatures(image, data, maxFaces, minFaceScale);</div>
</div><!-- fragment --><p>After this call, n contains the number of faces actually detected. The first n members of the data array are filled with resulting data for each detected face. Please refer to the <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> documentation for detailed description of returned parameters. If maxFaces is smaller than the number of faces actually present in the image, the function will return only first maxFaces detected faces.</p>
<p>VsImage is the image storage class similar to IplImage from OpenCV, it has the same structure and members so it can be used like IplImage. Please refer to OpenCV documentation for details of accessing IplImage data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</p>
<p>Following image formats are supported:</p><ul>
<li>VISAGE_FRAMEGRABBER_FMT_RGB: each pixel of the image is represented by three bytes representing red, green and blue channels, respectively.</li>
<li>VISAGE_FRAMEGRABBER_FMT_RGBA: each pixel of the image is represented by four bytes representing red, green, blue and alpha (ignored) channels, respectively.</li>
<li>VISAGE_FRAMEGRABBER_FMT_LUMINANCE: each pixel of the image is represented by one byte representing the luminance (gray level) of the image. Origin must be:</li>
<li>VISAGE_FRAMEGRABBER_ORIGIN_TL: Origin is the top left pixel of the image. Pixels are ordered row-by-row starting from top left.</li>
</ul>
<p>Note that the input image is internally converted to grayscale.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>the input image. </td></tr>
    <tr><td class="paramname">output</td><td>pointer to an array of <a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects in which the results will be returned. </td></tr>
    <tr><td class="paramname">maxFaces</td><td>maximum number of faces to be detected </td></tr>
    <tr><td class="paramname">minFaceScale</td><td>scale of smallest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height)) </td></tr>
    <tr><td class="paramname">maxFaceScale</td><td>scale of largest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height)) </td></tr>
    <tr><td class="paramname">outputOnly2DFeatures</td><td>if set, detection time will be reduced and only FeaturePoints2D will be returned </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>number of detected faces (0 or more)</dd></dl>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="structVisageSDK_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> </dd></dl>

<p>Referenced by <a class="el" href="VisageFaceRecognitionWrapper_8cpp_source.html#l00101">createGallery()</a>, <a class="el" href="VisageFeaturesDetectorWrapper_8cpp_source.html#l00133">Java_com_visagetechnologies_facedetectdemo_ImageDetectorView_DetectFeatures()</a>, and <a class="el" href="VisageFaceRecognitionWrapper_8cpp_source.html#l00195">Java_com_visagetechnologies_facedetectdemo_ImageDetectorView_recognizeFace()</a>.</p>

</div>
</div>
<a class="anchor" id="ad23a5d91f896b82fa7f88dc3b9532e1a"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool VisageSDK::VisageFeaturesDetector::Initialize </td>
          <td>(</td>
          <td class="paramtype">const char *&#160;</td>
          <td class="paramname"><em>path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialise the feature detector. </p>
<p>Several data files are needed for facial features detection and the path to the data folder containing these data files must be passed to the initialization function, for example:</p>
<div class="fragment"><div class="line">std::string dataPath(<span class="stringliteral">&quot;.&quot;</span>); <span class="comment">//Assuming the current working folder contains data files(from &quot;bdtsdata&quot; folder).   </span></div>
<div class="line"></div>
<div class="line">m_Detector-&gt;Initialize(dataPath.c_str());</div>
</div><!-- fragment --><p>The data folder must contain:</p><ul>
<li>a subfolder "bdtsdata" with complete contents as provided in visage|SDK;</li>
<li>files candide3.fdp, candide3.wfm, jk_300.fdp, jk_300.wfm and FaceDetector.cfg.</li>
</ul>
<p>In visage|SDK, the data folder with necessary files is Samples/data. These files must be distributed with any application using <a class="el" href="classVisageSDK_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">path</td><td>the path to the detector data files </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>true if successful </dd></dl>

<p>Referenced by <a class="el" href="VisageFeaturesDetectorWrapper_8cpp_source.html#l00088">Java_com_visagetechnologies_facedetectdemo_DetectorActivity_DetectorInit()</a>, and <a class="el" href="VisageFaceRecognitionWrapper_8cpp_source.html#l00150">Java_com_visagetechnologies_facedetectdemo_RecognitionActivity_initRecognition()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="VisageFeaturesDetector_8h_source.html">VisageFeaturesDetector.h</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.10
</small></address>
</body>
</html>
