<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.13"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>visageSDK: VisageCSWrapper.VisageFeaturesDetector Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">visageSDK
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.13 -->
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',false,false,'search.php','Search');
});
</script>
<div id="main-nav"></div>
<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceVisageCSWrapper.html">VisageCSWrapper</a></li><li class="navelem"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html">VisageFeaturesDetector</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classVisageCSWrapper_1_1VisageFeaturesDetector-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">VisageCSWrapper.VisageFeaturesDetector Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p>Faces and facial features detector implementation.  
 <a href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#details">More...</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a4919285d0271319971e46c15478bf03e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a4919285d0271319971e46c15478bf03e">VisageFeaturesDetector</a> ()</td></tr>
<tr class="memdesc:a4919285d0271319971e46c15478bf03e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor.  <a href="#a4919285d0271319971e46c15478bf03e">More...</a><br /></td></tr>
<tr class="separator:a4919285d0271319971e46c15478bf03e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0cee1e3f8bd70b073bacca11c4b552ab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a0cee1e3f8bd70b073bacca11c4b552ab">VisageFeaturesDetector</a> (String path)</td></tr>
<tr class="memdesc:a0cee1e3f8bd70b073bacca11c4b552ab"><td class="mdescLeft">&#160;</td><td class="mdescRight">Constructor that receives path to the "bdtsdata" folder.  <a href="#a0cee1e3f8bd70b073bacca11c4b552ab">More...</a><br /></td></tr>
<tr class="separator:a0cee1e3f8bd70b073bacca11c4b552ab"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a031f89deece3073adf0f982d9e0ab84a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a031f89deece3073adf0f982d9e0ab84a">~VisageFeaturesDetector</a> ()</td></tr>
<tr class="memdesc:a031f89deece3073adf0f982d9e0ab84a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Destructor.  <a href="#a031f89deece3073adf0f982d9e0ab84a">More...</a><br /></td></tr>
<tr class="separator:a031f89deece3073adf0f982d9e0ab84a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abac797f76a56155d2864f630f1b9bfbd"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#abac797f76a56155d2864f630f1b9bfbd">Initialize</a> (String path)</td></tr>
<tr class="memdesc:abac797f76a56155d2864f630f1b9bfbd"><td class="mdescLeft">&#160;</td><td class="mdescRight">Initialise the feature detector.  <a href="#abac797f76a56155d2864f630f1b9bfbd">More...</a><br /></td></tr>
<tr class="separator:abac797f76a56155d2864f630f1b9bfbd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d75cb1cb344205687ffde6c79860d81"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a5d75cb1cb344205687ffde6c79860d81">DetectFacialFeatures</a> (<a class="el" href="structVisageCSWrapper_1_1VSImage.html">VSImage</a> frame, <a class="el" href="structVisageCSWrapper_1_1FaceData.html">FaceData</a>[] output, float minFaceScale=0.1f, float maxFaceScale=1.0f, bool outputOnly2DFeatures=false)</td></tr>
<tr class="separator:a5d75cb1cb344205687ffde6c79860d81"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a96a43aa47360e279eccc6981405e3a1e"><td class="memItemLeft" align="right" valign="top">int&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a96a43aa47360e279eccc6981405e3a1e">DetectFaces</a> (<a class="el" href="structVisageCSWrapper_1_1VSImage.html">VSImage</a> frame, VSRect[] faces, float minFaceScale=0.1f, float maxFaceScale=1.0f, bool useRefinementStep=true)</td></tr>
<tr class="separator:a96a43aa47360e279eccc6981405e3a1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Faces and facial features detector implementation. </p>
<p>This class detects one or more faces and their facial features in an image. The input is an image bitmap or an image file in one of the supported file formats: JPEG, PNG, BMP or PPM. The results are, for each detected face, the 3D head pose, gaze direction, eye closure, the coordinates of facial feature points, e.g. chin tip, nose tip, lip corners etc. and 3D face model fitted to the face. The results are returned in one or more <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects, one for each detected face. Please refer to the <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> documentation for detailed description of returned data.</p>
<p>To use the detector, first initialise it by calling the function <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#abac797f76a56155d2864f630f1b9bfbd">Initialize()</a>. Alternatively, data path can be passed to the constructor. Data path represent a relative path from the working directory to the "bdtsdata" directory that contains <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a> data files. Finally, call the function <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a5d75cb1cb344205687ffde6c79860d81">DetectFacialFeatures()</a> to perform facial features detection on the image.</p>
<p>The path to the folder "bdtsdata" (located in Samples/data) must be passed to the initialization function, for example:</p>
<div class="fragment"><div class="line">gVisageFeaturesDetector = <span class="keyword">new</span> <a class="code" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#a4919285d0271319971e46c15478bf03e">VisageFeaturesDetector</a>(<span class="stringliteral">@&quot;..\Samples\data\bdtsdata&quot;</span>);</div></div><!-- fragment --><p>Additionally, the following files (located in Samples/data) are expected to be located in the same folder as the /bdtsdata folder: candide3.fdp, candide3.wfm, Face Detector.cfg. The whole "bdtsdata" folder and 3 additional files must be distributed with an application using <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a>, and its path passed to the initialization function.</p>

<p class="definition">Definition at line <a class="el" href="VisageFeaturesDetector_8cs_source.html#l00029">29</a> of file <a class="el" href="VisageFeaturesDetector_8cs_source.html">VisageFeaturesDetector.cs</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a4919285d0271319971e46c15478bf03e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4919285d0271319971e46c15478bf03e">&#9670;&nbsp;</a></span>VisageFeaturesDetector() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">VisageCSWrapper.VisageFeaturesDetector.VisageFeaturesDetector </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor. </p>

</div>
</div>
<a id="a0cee1e3f8bd70b073bacca11c4b552ab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0cee1e3f8bd70b073bacca11c4b552ab">&#9670;&nbsp;</a></span>VisageFeaturesDetector() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">VisageCSWrapper.VisageFeaturesDetector.VisageFeaturesDetector </td>
          <td>(</td>
          <td class="paramtype">String&#160;</td>
          <td class="paramname"><em>path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Constructor that receives path to the "bdtsdata" folder. </p>
<p>Using this method, there is no need to call <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#abac797f76a56155d2864f630f1b9bfbd">Initialize()</a>. For more information about data files required for facial features detection, please take a look at <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html#abac797f76a56155d2864f630f1b9bfbd">Initialize()</a>. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">path</td><td>The path to the detector data files.</td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a031f89deece3073adf0f982d9e0ab84a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a031f89deece3073adf0f982d9e0ab84a">&#9670;&nbsp;</a></span>~VisageFeaturesDetector()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">VisageCSWrapper.VisageFeaturesDetector.~VisageFeaturesDetector </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Destructor. </p>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a96a43aa47360e279eccc6981405e3a1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a96a43aa47360e279eccc6981405e3a1e">&#9670;&nbsp;</a></span>DetectFaces()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageCSWrapper.VisageFeaturesDetector.DetectFaces </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structVisageCSWrapper_1_1VSImage.html">VSImage</a>&#160;</td>
          <td class="paramname"><em>frame</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">VSRect []&#160;</td>
          <td class="paramname"><em>faces</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>minFaceScale</em> = <code>0.1f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>maxFaceScale</em> = <code>1.0f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>useRefinementStep</em> = <code>true</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p></p>
<p>Performs face detection in a still image.</p>
<p>The algorithm detects one or more faces. For each detected face a square facial bounding box is returned.</p>
<p>The results are returned in form of VsRect objects. An array of VsRect objects passed to this method as output parameter should be allocated to maxFaces size. For example:</p>
<div class="fragment"><div class="line">boundingBoxArray = <span class="keyword">new</span> VSRect[MAX_FACES];</div><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; MAX_FACES; ++i)</div><div class="line">{</div><div class="line">    boundingBoxArray[i] = <span class="keyword">new</span> VSRect();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> (gVisageFeaturesDetector.Initialized)</div><div class="line">{</div><div class="line">    numFaces = gVisageFeaturesDetector.DetectFaces(frame, boundingBoxArray);</div><div class="line">}</div></div><!-- fragment --><p>After this call, n contains the number of detected faces. The first n members of the faces array are filled with resulting bounding boxes for each detected face.</p>
<p>VsImage is the image storage class similar to IplImage from OpenCV, it has the same structure and members so it can be used like IplImage. Please refer to OpenCV documentation for details of accessing IplImage data members; the basic members are the size of the image (frame-&gt;width, frame-&gt;height) and the pointer to the actual pixel data of the image (frame-&gt;imageData).</p>
<p>Following image formats are supported:</p><ul>
<li>VISAGE_FORMAT.RGB: each pixel of the image is represented by three bytes representing red, green and blue channels, respectively.</li>
<li>VISAGE_FORMAT.RGBA: each pixel of the image is represented by four bytes representing red, green, blue and alpha (ignored) channels, respectively.</li>
<li>VISAGE_FORMAT.LUMINANCE: each pixel of the image is represented by one byte representing the luminance (gray level) of the image. Origin must be:</li>
<li>VISAGE_ORIGIN.TL: Origin is the top left pixel of the image. Pixels are ordered row-by-row starting from top left.</li>
</ul>
<p>Note that the input image is internally converted to grayscale.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>The input image.</td></tr>
    <tr><td class="paramname">faces</td><td>Pointer to an array of VSRect objects in which the results will be returned.</td></tr>
    <tr><td class="paramname">minFaceScale</td><td>Scale of smallest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height))</td></tr>
    <tr><td class="paramname">maxFaceScale</td><td>Scale of largest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height))</td></tr>
    <tr><td class="paramname">useRefinementStep</td><td>If set to true, additional refinement algorithm will be used resulting with more precise facial bounding boxes and lower FPR, but higher detection time </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Number of detected faces (0 or more)</dd></dl>

</div>
</div>
<a id="a5d75cb1cb344205687ffde6c79860d81"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d75cb1cb344205687ffde6c79860d81">&#9670;&nbsp;</a></span>DetectFacialFeatures()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">int VisageCSWrapper.VisageFeaturesDetector.DetectFacialFeatures </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structVisageCSWrapper_1_1VSImage.html">VSImage</a>&#160;</td>
          <td class="paramname"><em>frame</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structVisageCSWrapper_1_1FaceData.html">FaceData</a> []&#160;</td>
          <td class="paramname"><em>output</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>minFaceScale</em> = <code>0.1f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float&#160;</td>
          <td class="paramname"><em>maxFaceScale</em> = <code>1.0f</code>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool&#160;</td>
          <td class="paramname"><em>outputOnly2DFeatures</em> = <code>false</code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p></p>
<p>Performs faces and facial features detection in a still image.</p>
<p>The algorithm detects one or more faces and their features. The results are, for each detected face, the 3D head pose, gaze direction, eye closure, the coordinates of facial feature points (e.g. chin tip, nose tip, lip corners etc.) and 3D face model fitted to the face.</p>
<p>The results are returned in form of <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects. An array of <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects passed to this method as output parameter should be allocated to maxFaces size. For example:</p>
<div class="fragment"><div class="line">dataArray = <span class="keyword">new</span> FaceData[MAX_FACES];</div><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> i = 0; i &lt; MAX_FACES; ++i)</div><div class="line">{</div><div class="line">    dataArray[i] = <span class="keyword">new</span> FaceData();</div><div class="line">}</div><div class="line"></div><div class="line"><span class="keywordflow">if</span> (gVisageFeaturesDetector.Initialized)</div><div class="line">{</div><div class="line">    numFaces = gVisageFeaturesDetector.DetectFacialFeatures(frame, dataArray);</div><div class="line">}</div></div><!-- fragment --><p>After this call, n contains the number of faces actually detected. The first n members of the data array are filled with resulting data for each detected face. Please refer to the <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> documentation for detailed description of returned parameters.</p>
<p>Following image formats are supported:</p><ul>
<li>VISAGE_FORMAT.RGB: each pixel of the image is represented by three bytes representing red, green and blue channels, respectively.</li>
<li>VISAGE_FORMAT.RGBA: each pixel of the image is represented by four bytes representing red, green, blue and alpha (ignored) channels, respectively.</li>
<li>VISAGE_FORMAT.LUMINANCE: each pixel of the image is represented by one byte representing the luminance (gray level) of the image. Origin must be:</li>
<li>VISAGE_ORIGIN.TL: Origin is the top left pixel of the image. Pixels are ordered row-by-row starting from top left.</li>
</ul>
<p>Note that the input image is internally converted to grayscale.</p>
<dl class="section see"><dt>See also</dt><dd><a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a></dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">frame</td><td>The input image.</td></tr>
    <tr><td class="paramname">output</td><td>Pointer to an array of <a class="el" href="structVisageCSWrapper_1_1FaceData.html" title="Face data structure, used as container for all face tracking and detection results. ">FaceData</a> objects in which the results will be returned.</td></tr>
    <tr><td class="paramname">minFaceScale</td><td>Scale of smallest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height))</td></tr>
    <tr><td class="paramname">maxFaceScale</td><td>Scale of smallest face to be searched for, defined as decimal fraction [0.0 - 1.0] of input image size (min(width, height))</td></tr>
    <tr><td class="paramname">outputOnly2DFeatures</td><td>If set, detection time will be reduced and only featurePoints2D will be returned.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Number of detected faces (0 or more)</dd></dl>

</div>
</div>
<a id="abac797f76a56155d2864f630f1b9bfbd"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abac797f76a56155d2864f630f1b9bfbd">&#9670;&nbsp;</a></span>Initialize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">bool VisageCSWrapper.VisageFeaturesDetector.Initialize </td>
          <td>(</td>
          <td class="paramtype">String&#160;</td>
          <td class="paramname"><em>path</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Initialise the feature detector. </p>
<p>The path to the folder "bdtsdata" (located in Samples/data) must be passed to the initialization function, for example: </p><div class="fragment"><div class="line">std::string dataPath(<span class="stringliteral">@&quot;..\Samples\data\bdtsdata&quot;</span>);</div><div class="line"></div><div class="line">gVisageFeaturesDetector.Initialize(dataPath.c_str());</div></div><!-- fragment --><p>The data folder must contain:</p><ul>
<li>a subfolder "bdtsdata" with complete contents as provided in visage|SDK;</li>
<li>files: candide3.fdp, candide3.wfm, jk_300.fdp, jk_300.wfm and FaceDetector.cfg.</li>
</ul>
<p>In visage|SDK, the data folder with necessary files is Samples/data. These files must be distributed with any application using <a class="el" href="classVisageCSWrapper_1_1VisageFeaturesDetector.html" title="Faces and facial features detector implementation. ">VisageFeaturesDetector</a>.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">path</td><td>The path to the detector data files.</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>True if successful.</dd></dl>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li><a class="el" href="VisageFeaturesDetector_8cs_source.html">VisageFeaturesDetector.cs</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.13
</small></address>
</body>
</html>
