<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Introduction</title>
<link href="css/main.css" rel="stylesheet" type="text/css" />
</head>

<body>
<h1>Facial Animation Unity Demo sample project</h1>

<p>
The FacialAnimationUnityDemo sample project demonstrates the integration of visage|SDK with Unity game engine and is aimed at developers starting to use face tracking functionality of visage|SDK to drive facial animation using blendshapes and bones in the Unity game engine.
</p>
<p>
The sample project shows how to animate a character and make it mimic the users facial expressions using action units from visage|SDK. Developers may use parts of this project to speed up their own
development in Unity using visage|SDK or use this application as a starting point for own projects.
</p>

<h2>Building and running the project</h2>

<p>
The files related to FacialAnimationUnityDemo sample project are located in the Samples/MacOSX/FacialAnimationUnityDemo
subfolder of the visage|SDK for Mac OS X folder.<br/><br/>
Prerequisites to running the sample project are:
<ul>
<li>Xcode (version 8.3.x)</li>
<li>Unity (version 5.6.x)</li>
</ul>

To build and run FacialAnimationUnityDemo sample two steps are involved: creating the Unity project from the provided
Unity package and building the application.<br/><br/>

</p>

<h3>Step 1. Creating the Unity project from Unity package</h3>

<p>
To create the Unity project from provided Unity package follow these steps:<br/>
<ol>
<li>Open Unity</li> <br/>
<li>Create a new Unity project</li> <br/>
<li>Import <b> FacialAnimationUnityDemo.unitypackage </b>  that is provided in the Samples/MacOSX/FacialAnimationUnityDemo folder. <br/> 
	This is done in Unity by selecting Assets->Import Package->Custom Package... item from the menu. <br/> 
	All the assets that are used by the example project will be imported into the new project.</li> <br/>
<li>Create new folder <b>StreamingAssets/Visage Tracker</b>  under <b>Assets</b> folder in your Unity project and copy following files from visageSDK-MacOS/Samples/data folder:
<ul>
<li>bdtsdata folder</li>
<li>candide3.fdp</li>
<li>candide3.wfm</li>
<li>jk_300.fdp</li>
<li>jk_300.wfm</li>
<li>Facial Features Tracker - High.cfg</li>
<li>Facial Features Tracker - Low.cfg</li>
<li>Head Tracker.cfg</li>
</ul>
</li><br/>
 <b>NOTE:</b> If you have a license key file, add it also to the <b>StreamingAssets/Visage Tracker</b> folder and refer to the <a href="licensing.html#include_license">Including the License Key File in your application</a> section for more details.<br/>  <br/> 

<li>Create new folder <b>Plugins</b> under <b>Assets</b> folder in your Unity project and copy <b>VisageTrackerUnityPlugin.bundle</b> from visageSDK-MacOS/lib folder.
</li><br/>	
<li>Select and open the Main scene (Jones), located in the Project's Assets/Visage Tracker/Jones/.</li>
</ol>
</p>

<h3>Step 2. Building the application</h3>
<p>
To build the application follow these steps:
<ol>
<li>Build the application by selecting File->Build settings... and under Platform choose PC and Mac Standalone and set Mac OS X as target platform.</li> <br/>
<li>Go to Player Settings, uncheck the box next to <b>Auto Graphics API</b> for Mac and remove <b>OpenGLCore</b> from the list.</li> <br/>
<li>Press the Build button to generate the project.</li> <br/>
</ol>
</p>

<h2>Using the sample application</h2>

<p>
To start the application, double-click on FacialAnimationUnity.app.
<br/>
<br/>
As soon as the application starts, tracking will begin. When a face is found in the camera frame, the character will start moving - mimicking the user's facial expressions. Try opening your mouth, smiling or moving your eyebrows.<br/>
Available buttons are: Play/Pause in the lower left corner, Switch camera in the lower right corner and Normal/Mask in the upper right corner of the screen.
<br/>
<br/>
<b> NOTE:</b>  Without the valid License Key tracking will stop after 1 minute. Appropriate message will appear on the screen to inform the user before the start of the tracking and after the tracking time expires.<br/> Please refer to the <a href="licensing.html#include_license">Including the License Key File in your application</a> section for details.
</p>

<h2>Implementation overview</h2>
<p>
The project consists of a main scene with the Unity’s GameObjects that provide different functionalities. A GameObject
is the main building block of a scene in Unity. It consists of different Components and can parent other GameObjects.
Manipulation of GameObjects is done with Scripts. It is recommended for developers to get familiar with Unity basics
before continuing. The integration with visage|SDK is done through the VisageTrackerUnityPlugin.
</p>

<h4>Visage Tracker GameObject</h4>
<p>
The core of the example is the Visage Tracker GameObject. It handles communication with the tracker
(starts it and gets results from it). The behaviour of the script can be modified by changing its properties and the script
code. Other properties can be added as well. The existing Visage Tracker script properties of interest are as follows:<br/>
• Config File OSX: filename of the tracker configuration file (see the <a href="VisageTracker Configuration Manual.pdf">VisageTracker Configuration manual</a> for information on modifying the tracker configuration) that will be used by the tracker for Mac OS X<br/>
• BindingConfigurations: list of binding configurations (see the Binding Configuration section on this page) used in the scene<br/>
</p>

<h4>Cameras</h4>
<p>
There are two cameras in the scene, one for displaying the character (Main Camera) and other for the background (Background Camera).
The main camera "Field of View" is automatically set according to the Visage Tracker focus (camera_focus parameter in
configuration file).
</p>

<h4>Jones</h4>
<p>
Jones is the character with defined blendshape animations which are controlled using the a binding configuration and bones
which are controlled using the <i>Visage Tracker/Jones/Scripts/Movement.cs</i> script. The visage|SDK provides relevant information about facial expressions through action units. Their values are then mapped to specific blendshapes using 
binding configurations in the <i>VisageTracker.cs</i> script. For more information on creating characters with such blendshapes, consult the <a href="modeling_guide.pdf" target="_blank">Modeling Guide</a>.
</p>

<h4>Binding Configuration</h4>
<p>
Binding configurations map action unit values to specific blendshapes and animate them. A reference binding configuration used to animate Jones is located in <i>Visage Tracker/Jones/jones.bind.txt</i>. <br/>
<i>ActionUnitBinding.cs</i> components are created based on the <i>VisageTracker.cs</i> Binding Configuration list in the current scene at runtime. They receive action unit data from the Visage Tracker component and map them to [0,1] values based on the info given in the binding configuration. You can omit the binding configuration in the Visage Tracker GameObject and create the <i>ActionUnitBinding.cs</i> components manually for more control.
</p>

<h4>Visage Tracker Unity Plugin</h4>
<p>
The integration of visage|SDK face tracking with Unity is done through a plugin that wraps native code calls and
provides functions that can be called from Unity scripts. For more information about the plugin including it's source code, see the <a href="unity_plugin.html">VisageTrackerUnityPlugin</a> project and its documentation.
</p>

</body>
</html>
